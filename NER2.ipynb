{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Neo4j database cleared.\n",
      "INFO:root:Processing file: paper_16_paragraphs\\text_1.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "ERROR:root:Error generating embedding: 'CreateEmbeddingResponse' object is not subscriptable\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing file: paper_16_paragraphs\\text_10.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "ERROR:root:Error generating embedding: 'CreateEmbeddingResponse' object is not subscriptable\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing file: paper_16_paragraphs\\text_11.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "ERROR:root:Error generating embedding: 'CreateEmbeddingResponse' object is not subscriptable\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing file: paper_16_paragraphs\\text_12.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "ERROR:root:Error generating embedding: 'CreateEmbeddingResponse' object is not subscriptable\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing file: paper_16_paragraphs\\text_13.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "ERROR:root:Error generating embedding: 'CreateEmbeddingResponse' object is not subscriptable\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing file: paper_16_paragraphs\\text_14.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "ERROR:root:Error generating embedding: 'CreateEmbeddingResponse' object is not subscriptable\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing file: paper_16_paragraphs\\text_15.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "ERROR:root:Error generating embedding: 'CreateEmbeddingResponse' object is not subscriptable\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing file: paper_16_paragraphs\\text_16.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "ERROR:root:Error generating embedding: 'CreateEmbeddingResponse' object is not subscriptable\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing file: paper_16_paragraphs\\text_17.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "ERROR:root:Error generating embedding: 'CreateEmbeddingResponse' object is not subscriptable\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "ERROR:root:Error generating relationships: Invalid \\escape: line 24 column 230 (char 1085)\n",
      "INFO:root:Processing file: paper_16_paragraphs\\text_18.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "ERROR:root:Error generating embedding: 'CreateEmbeddingResponse' object is not subscriptable\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing file: paper_16_paragraphs\\text_19.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "ERROR:root:Error generating embedding: 'CreateEmbeddingResponse' object is not subscriptable\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing file: paper_16_paragraphs\\text_2.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "ERROR:root:Error generating embedding: 'CreateEmbeddingResponse' object is not subscriptable\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing file: paper_16_paragraphs\\text_20.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "ERROR:root:Error generating embedding: 'CreateEmbeddingResponse' object is not subscriptable\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing file: paper_16_paragraphs\\text_21.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "ERROR:root:Error generating embedding: 'CreateEmbeddingResponse' object is not subscriptable\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing file: paper_16_paragraphs\\text_22.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "ERROR:root:Error generating embedding: 'CreateEmbeddingResponse' object is not subscriptable\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing file: paper_16_paragraphs\\text_23.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "ERROR:root:Error generating embedding: 'CreateEmbeddingResponse' object is not subscriptable\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "ERROR:root:Error generating relationships: Invalid \\escape: line 48 column 82 (char 1891)\n",
      "INFO:root:Processing file: paper_16_paragraphs\\text_24.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "ERROR:root:Error generating embedding: 'CreateEmbeddingResponse' object is not subscriptable\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List, Tuple, Dict\n",
    "from openai import OpenAI\n",
    "from neo4j import GraphDatabase\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from transformers import pipeline\n",
    "import spacy\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Initialize NER model\n",
    "def load_ner_model(model_name: str):\n",
    "    return pipeline(\n",
    "        \"token-classification\",\n",
    "        model=model_name,\n",
    "        aggregation_strategy=\"simple\"\n",
    "    )\n",
    "\n",
    "# Load spaCy model\n",
    "def load_spacy_model():\n",
    "    try:\n",
    "        return spacy.load(\"en_core_web_sm\")\n",
    "    except OSError:\n",
    "        print(\"Downloading spaCy language model...\")\n",
    "        spacy.cli.download(\"en_core_web_sm\")\n",
    "        return spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Generate OpenAI embeddings\n",
    "def generate_openai_embedding(text: str, openai_client) -> List[float]:\n",
    "    try:\n",
    "        response = openai_client.embeddings.create(\n",
    "            model=\"text-embedding-ada-002\",\n",
    "            input=text\n",
    "        )\n",
    "        return response['data'][0]['embedding']\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error generating embedding: {e}\")\n",
    "        return []\n",
    "\n",
    "# Split text into chunks\n",
    "def split_text_into_chunks(text: str, max_length: int = 512) -> List[str]:\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i + max_length]) for i in range(0, len(words), max_length)]\n",
    "\n",
    "# Extract entities using both models\n",
    "def extract_entities(text: str, ner_model, nlp) -> List[Tuple[str, str]]:\n",
    "    ner_results = ner_model(text)\n",
    "    entities = [(res[\"word\"], res[\"entity_group\"]) for res in ner_results]\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    spacy_entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    \n",
    "    all_entities = entities + spacy_entities\n",
    "    unique_entities = list({(e.lower(), t): (e, t) for e, t in all_entities}.values())\n",
    "    return unique_entities\n",
    "\n",
    "# Generate relationships using OpenAI\n",
    "def generate_relations(text: str, entities: List[Tuple[str, str]], openai_client, openai_model: str) -> List[Dict]:\n",
    "    entities_str = \"\\n\".join([\n",
    "        f\"{idx+1}. {entity} (Type: {entity_type})\"\n",
    "        for idx, (entity, entity_type) in enumerate(entities)\n",
    "    ])\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "        You are an expert in knowledge graph construction. Identify relationships between these entities:\n",
    "        \n",
    "        ### Text:\n",
    "        {text}\n",
    "        \n",
    "        ### Entities:\n",
    "        {entities_str}\n",
    "        \n",
    "        Output relationships in JSON format:\n",
    "        [\n",
    "            {{\n",
    "                \"source\": \"Entity1\",\n",
    "                \"source_type\": \"Type1\",\n",
    "                \"target\": \"Entity2\",\n",
    "                \"target_type\": \"Type2\",\n",
    "                \"relationship\": \"RELATIONSHIP_TYPE\",\n",
    "                \"evidence\": \"Evidence from the text\"\n",
    "            }}.\n",
    "        ]\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=openai_model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=1500,\n",
    "            temperature=0.1\n",
    "        )\n",
    "        raw_content = response.choices[0].message.content.strip()\n",
    "        relations = json.loads(raw_content)\n",
    "        return relations if isinstance(relations, list) else []\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error generating relationships: {e}\")\n",
    "        return []\n",
    "\n",
    "# Create nodes in Neo4j\n",
    "def create_nodes_with_embeddings(tx, entity_metadata):\n",
    "    for data in entity_metadata:\n",
    "        entity, entity_type = data[\"entity\"]\n",
    "        embedding = data[\"embedding\"]\n",
    "        chunk_text = data[\"chunk_text\"]\n",
    "        description = chunk_text[:200]  # First 200 characters as description\n",
    "        \n",
    "        tx.run(\n",
    "            \"\"\"\n",
    "            MERGE (n:Entity {name: $name, type: $type})\n",
    "            SET n.embedding = $embedding,\n",
    "                n.chunk = $chunk,\n",
    "                n.description = $description\n",
    "            \"\"\",\n",
    "            {\"name\": entity, \"type\": entity_type, \"embedding\": embedding, \"chunk\": chunk_text, \"description\": description}\n",
    "        )\n",
    "\n",
    "\n",
    "# Create relationships in Neo4j\n",
    "def create_relationships(tx, relations):\n",
    "    for relation in relations:\n",
    "        relationship_type = relation[\"relationship\"].replace(\" \", \"_\").upper()\n",
    "        query = f\"\"\"\n",
    "        MATCH (source:Entity {{name: $source}})\n",
    "        MATCH (target:Entity {{name: $target}})\n",
    "        MERGE (source)-[r:`{relationship_type}`]->(target)\n",
    "        SET r.evidence = $evidence\n",
    "        \"\"\"\n",
    "        tx.run(query, {\n",
    "            \"source\": relation[\"source\"],\n",
    "            \"target\": relation[\"target\"],\n",
    "            \"evidence\": relation.get(\"evidence\", \"No specific evidence\")\n",
    "        })\n",
    "\n",
    "# Clear Neo4j database\n",
    "def clear_neo4j_database(uri: str, username: str, password: str):\n",
    "    driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "    with driver.session() as session:\n",
    "        session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "        logging.info(\"Neo4j database cleared.\")\n",
    "    driver.close()\n",
    "\n",
    "def process_text_with_embeddings(text: str, ner_model, nlp, openai_client, openai_model, neo4j_config):\n",
    "    chunks = split_text_into_chunks(text)\n",
    "    all_entities = []\n",
    "    all_relations = []\n",
    "    entity_metadata = []  # List to store entities with corresponding embeddings and chunk texts\n",
    "\n",
    "    for chunk in chunks:\n",
    "        embedding = generate_openai_embedding(chunk, openai_client)\n",
    "        entities = extract_entities(chunk, ner_model, nlp)\n",
    "        relations = generate_relations(chunk, entities, openai_client, openai_model)\n",
    "        \n",
    "        for entity in entities:\n",
    "            entity_metadata.append({\n",
    "                \"entity\": entity,\n",
    "                \"embedding\": embedding,\n",
    "                \"chunk_text\": chunk\n",
    "            })\n",
    "        \n",
    "        all_entities.extend(entities)\n",
    "        all_relations.extend(relations)\n",
    "\n",
    "    # Deduplicate entities and align metadata\n",
    "    unique_entities = list(set(all_entities))\n",
    "    unique_relations = {frozenset((rel[\"source\"], rel[\"target\"])): rel for rel in all_relations}.values()\n",
    "\n",
    "    # Prepare final metadata for Neo4j\n",
    "    final_metadata = [\n",
    "        {\n",
    "            \"entity\": entity,\n",
    "            \"embedding\": next(\n",
    "                (meta[\"embedding\"] for meta in entity_metadata if meta[\"entity\"] == entity), []\n",
    "            ),\n",
    "            \"chunk_text\": next(\n",
    "                (meta[\"chunk_text\"] for meta in entity_metadata if meta[\"entity\"] == entity), \"\"\n",
    "            )\n",
    "        }\n",
    "        for entity in unique_entities\n",
    "    ]\n",
    "\n",
    "    driver = GraphDatabase.driver(neo4j_config[\"uri\"], auth=(neo4j_config[\"username\"], neo4j_config[\"password\"]))\n",
    "    with driver.session() as session:\n",
    "        # Add nodes with embeddings and text metadata\n",
    "        session.execute_write(create_nodes_with_embeddings, final_metadata)\n",
    "        session.execute_write(create_relationships, list(unique_relations))\n",
    "    driver.close()\n",
    "\n",
    "    return unique_entities, list(unique_relations)\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    text_file_path = 'data/sample.txt' \n",
    "    neo4j_url = \"bolt://localhost:7687\" \n",
    "    neo4j_username = \"neo4j\" \n",
    "    neo4j_password = \"123456789\" \n",
    "    ner_model_name = \"Clinical-AI-Apollo/Medical-NER\" \n",
    "    openai_model_name = \"gpt-4\"\n",
    "\n",
    "\n",
    "    # Load models\n",
    "    ner_model = load_ner_model(ner_model_name)\n",
    "    nlp = load_spacy_model()\n",
    "    openai_client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "    # Clear the Neo4j database\n",
    "    clear_neo4j_database(neo4j_url, neo4j_username, neo4j_password)\n",
    "\n",
    "    # Directory with text files\n",
    "    paper_text_dir = 'paper_16_paragraphs'\n",
    "    text_files = [os.path.join(paper_text_dir, file) for file in os.listdir(paper_text_dir) if file.endswith('.txt')]\n",
    "\n",
    "    for idx, text_file in enumerate(text_files):\n",
    "        db_name = f\"db_{idx + 1}\"\n",
    "        neo4j_config = {\n",
    "            \"uri\": neo4j_url,\n",
    "            \"username\": neo4j_username,\n",
    "            \"password\": neo4j_password,\n",
    "            \"database\": db_name\n",
    "        }\n",
    "        \n",
    "        with open(text_file, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "        \n",
    "        if not text.strip():  # Skip empty files\n",
    "            logging.warning(f\"File {text_file} is empty. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        logging.info(f\"Processing file: {text_file}\")\n",
    "        entities, relations = process_text_with_embeddings(\n",
    "            text, ner_model, nlp, openai_client, openai_model_name, neo4j_config\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
